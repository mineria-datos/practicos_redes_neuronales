---
title: "Guia 1"
author: "Grupo 3"
date: "9/28/2019"
output:
  html_document: default
---


```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(readr)
library(plotly)
library(foreach)

## ejecuciones multicore
#install.packages("doMC", repos="http://R-Forge.R-project.org")
library(doMC)
registerDoMC()
getDoParWorkers() 
source('./PerceptronSimple.R')
source('./PerceptronMulticapa.R')
source('./Particiones.R')
source('./LeavePOut.R')

calcular = TRUE

if(file.exists('./resultados.RData')) {
  load("./resultados.RData")
  calcular = FALSE
}

```

# Guía 1

## Ejercicio 1

Realice un programa que permita el entrenamiento y prueba de un perceptrón simple con una cantidad variable de entradas.

### Resolución del problema OR

 - Lectura de los patrones de entrenamiento

```{r message=FALSE}
OR_trn <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/OR_trn.csv", col_names = FALSE)
OR_tst <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/OR_tst.csv", col_names = FALSE)

```
 - Selección de parámetros y entrenamiento de perceptrón
 
Utilizamos las funciones implementadas en el archivo "PerceptronSimple.R"

```{r}
if (calcular) {
 salidaPerceptronOR <- entrenarPerceptron(OR_trn, maxEpocas = 10, critFinalizacion = 0.9)
}
# Modelo obtenido
salidaPerceptronOR

```
El entrenamiento nos devuelve la tasa obtenida en cada época y al final mostramos los valores de los pesos w que definen la recta del modelo. 

$pesos = [w_0, w_1, w_2, ...w_n]$

 - Graficas

```{r}
graficarRectaSeparacion(salidaPerceptronOR$W, OR_trn)
```

En la gráfica vemos como la recta del modelo separa el dominio según la clase.

 - Prueba con datos de test

```{r}
test <- aplicarPerceptron(salidaPerceptronOR$W, OR_tst)
test$tasa
```

Por ser este un problema sencillo donde las clases son separables por una recta, la tasa de aciertos en test nos da un 100%.

### Resolución del problema XOR

 - Lectura de los patrones de entrenamiento

```{r message=FALSE}
XOR_trn <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/XOR_trn.csv", col_names = FALSE)
XOR_tst <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/XOR_tst.csv", col_names = FALSE)
```
 - Selección de parámetros y entrenamiento de perceptrón

```{r}
if (calcular) {
  salidaPerceptronXOR <- entrenarPerceptron(XOR_trn, maxEpocas = 10, critFinalizacion = 0.8)
}
salidaPerceptronXOR

```

Vemos que luego de 10 épocas el perceptrón simple no logra resolver el problema del XOR, ni tampoco mejorar su tasa de aciertos.

 - Graficas

```{r}
graficarRectaSeparacion(salidaPerceptronXOR$W, XOR_trn)
```

En la gráfica vemos la recta obtenida que deja todos los patrones clasificados de igual manera.

 - Prueba con datos de test

```{r}
test <- aplicarPerceptron(salidaPerceptronXOR$W, XOR_tst)
test$tasa
```

Este problema no pudo ser resuelto por le perceptrón simple, la tasa de aciertos obtenida es peor que el azar.

### Preguntas:
 
 - ¿Pueden ser resueltos ambos problemas (OR y XOR) empleando un perceptrón simple? Justifique su respuesta.
 
 En los resultados obtenidos verificamos que no se puede resolver el problema XOR con el perceptrón simple porque no es posible dividir la clase con una recta que separe el dominio en dos.
 
 - ¿Qué efecto tiene la tasa de aprendizaje en el entrenamiento del perceptrón? Explique cómo este parámetro afecta a la actualización de la frontera de decisión
 
La tasa de aprendizaje nos permite variar cuanto se actualizan los valores de los pesos. Una tasa muy baja puede generar que el algoritmo demore mucho en llegar al mínimo, y una tasa muy alta puede generar que el algoritmo diverja y nunca llegue a un mínimo. 
En nuestro caso, se implementó una función que posee una tasa de aprendizaje de 0,05 (nu=0.05) por defecto y no fue necesario cambiarlo. 


## Ejercicio 2

### Punto a

 - Lectura de datos

```{r message=FALSE}
spheres1d10 <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/spheres1d10.csv", col_names = FALSE)
#Nombre de las columnas
colnames(spheres1d10)
#Dimenciones de los datos
dim(spheres1d10)
```
 - Grafica
 
```{r}
plot_ly(x=spheres1d10$X1, y=spheres1d10$X2, z=spheres1d10$X3, type="scatter3d", 
        mode="markers", color=spheres1d10$X4)
```

 - Generamos las particiones

Utilizamos la función implementada en el archivo "Particiones.R"

```{r}
particion_spheres1d10 <- generarNParticionesPorID(dataset = spheres1d10, nroParticiones = 5, 
                                                porcEntrenamiento = 0.8, semilla = 1, 
                                                clase = "X4")
```

Esta función nos devuelve un listado de 5 listas de ID para entrenamiento, de aproximadamente 800 elementos, y 5 listas de ID para prueba, de aproximadamente 200 elementos.

 - Generamos los modelos con el perceptrón simple.
 
```{r}
for (n in seq(1,5)) {
  print(glue::glue("Partición: {n}"))
  #Entrenamiento
  salidaPerceptron <- entrenarPerceptronSigmo(spheres1d10[particion_spheres1d10$trn[[n]],], 
                                   maxEpocas = 20, critFinalizacion = 0.8)
  print(glue::glue("Pesos: {salidaPerceptron$W}"))
  #Prueba
  test <- aplicarPerceptron(salidaPerceptron$W, spheres1d10[particion_spheres1d10$tst[[n]],])
  print(glue::glue("Tasa de aciertos en test: {test$tasa}"))
}
```
 
### Punto b

 - Lectura de datos

```{r message=FALSE}
spheres2d10 <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/spheres2d10.csv", col_names = FALSE)
spheres2d50 <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/spheres2d50.csv", col_names = FALSE)
spheres2d70 <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/spheres2d70.csv", col_names = FALSE)

```

 - Generamos las particiones
 
Llamamos a la función dos veces con dos semillas para obtener las 10 particiones. La función implementada genera las particiones sin reemplazo, con una relación 80/20 no se pueden generar más de 5 particiones.

```{r}
# 10%
particion_spheres2d10 <- generarNParticionesPorID(dataset = spheres2d10, nroParticiones = 5, 
                                                porcEntrenamiento = 0.8, semilla = 1, 
                                                clase = "X4")
particion_spheres2d10$trn <- c(particion_spheres2d10$trn, generarNParticionesPorID(
  dataset = spheres2d10, nroParticiones = 5, porcEntrenamiento = 0.8, semilla = 12, 
  clase = "X4")$trn)
particion_spheres2d10$tst <- c(particion_spheres2d10$tst, generarNParticionesPorID(
  dataset = spheres2d10, nroParticiones = 5, porcEntrenamiento = 0.8, semilla = 12, 
  clase = "X4")$tst)

# 50%
particion_spheres2d50 <- generarNParticionesPorID(dataset = spheres2d50, nroParticiones = 5, 
                                                porcEntrenamiento = 0.8, semilla = 1, 
                                                clase = "X4")
particion_spheres2d50$trn <- c(particion_spheres2d50$trn, generarNParticionesPorID(
  dataset = spheres2d50, nroParticiones = 5, porcEntrenamiento = 0.8, semilla = 12, 
  clase = "X4")$trn)
particion_spheres2d50$tst <- c(particion_spheres2d50$tst, generarNParticionesPorID(
  dataset = spheres2d50, nroParticiones = 5, porcEntrenamiento = 0.8, semilla = 12, 
  clase = "X4")$tst)

# 70%
particion_spheres2d70 <- generarNParticionesPorID(dataset = spheres2d70, nroParticiones = 5, 
                                                porcEntrenamiento = 0.8, semilla = 1, 
                                                clase = "X4")
particion_spheres2d70$trn <- c(particion_spheres2d70$trn, generarNParticionesPorID(
  dataset = spheres2d70, nroParticiones = 5, porcEntrenamiento = 0.8, semilla = 12, 
  clase = "X4")$trn)
particion_spheres2d70$tst <- c(particion_spheres2d70$tst, generarNParticionesPorID(
  dataset = spheres2d70, nroParticiones = 5, porcEntrenamiento = 0.8, semilla = 12, 
  clase = "X4")$tst)
```

 - Generamos los modelos con el perceptrón simple.
 
 -- Datos con desviaciones del 10%
 
```{r}
plot_ly(x=spheres2d10$X1, y=spheres2d10$X2, z=spheres2d10$X3, type="scatter3d", 
        mode="markers", color=spheres2d10$X4)
```
 
 
```{r}
tasaMedia <- 0
for (n in seq(1,10)) {
  print(glue::glue("Partición: {n}"))
  #Entrenamiento
  salidaPerceptron <- entrenarPerceptron(spheres2d10[particion_spheres2d10$trn[[n]],], 
                                   maxEpocas = 10, critFinalizacion = 0.79)
  print(glue::glue("Pesos: {salidaPerceptron$W}"))
  #Pruba
  test <- aplicarPerceptron(salidaPerceptron$W, spheres2d10[particion_spheres2d10$tst[[n]],])
  print(glue::glue("Tasa de aciertos en test: {test$tasa}"))
  tasaMedia <- tasaMedia + test$tasa
}
print(glue::glue("Tasa de aciertos media en test: {tasaMedia/10}"))
``` 
 
 -- Datos con desviaciones del 50%
 
```{r}
plot_ly(x=spheres2d50$X1, y=spheres2d50$X2, z=spheres2d50$X3, type="scatter3d", mode="markers", color=spheres2d50$X4)
```
 
 
```{r}
tasaMedia <- 0
for (n in seq(1,10)) {
  print(glue::glue("Partición: {n}"))
  #Entrenamiento
  salidaPerceptron <- entrenarPerceptron(spheres2d50[particion_spheres2d50$trn[[n]],], 
                                   maxEpocas = 5, critFinalizacion = 0.79)
  print(glue::glue("Pesos: {salidaPerceptron$W}"))
  #Pruba
  test <- aplicarPerceptron(salidaPerceptron$W, spheres2d50[particion_spheres2d50$tst[[n]],])
  print(glue::glue("Tasa de aciertos en test: {test$tasa}"))
  tasaMedia <- tasaMedia + test$tasa
}
print(glue::glue("Tasa de aciertos media en test: {tasaMedia/10}"))
```

 -- Datos con desviaciones del 70%
 
```{r}
plot_ly(x=spheres2d70$X1, y=spheres2d70$X2, z=spheres2d70$X3, type="scatter3d", mode="markers", color=spheres2d70$X4)
```
 
 
```{r}
tasaMedia <- 0
for (n in seq(1,10)) {
  print(glue::glue("Partición: {n}"))
  #Entrenamiento
  salidaPerceptron <- entrenarPerceptron(spheres2d70[particion_spheres2d70$trn[[n]],], 
                                   maxEpocas = 10, critFinalizacion = 0.77)
  print(glue::glue("Pesos: {salidaPerceptron$W}"))
  #Pruba
  test <- aplicarPerceptron(salidaPerceptron$W, spheres2d70[particion_spheres2d70$tst[[n]],])
  print(glue::glue("Tasa de aciertos en test: {test$tasa}"))
  tasaMedia <- tasaMedia + test$tasa
}
print(glue::glue("Tasa de aciertos media en test: {tasaMedia/10}"))
```



### Preguntas

 - ¿Qué beneficio supone el uso de validación cruzada?
 
 El uso de validación cruzada nos permite usar todos los datos para test y poder evaluar de mejor manera si el método utilizado para la generación del modelo es bueno.
 
 - ¿Qué ocurre con la tasa de acierto del perceptrón para los diferentes datasets del ejercicio 2b? Analice el desempeño al incrementarse la dispersión de los datos.
 
Al aumentar la dispersión de los datos, disminuye la tasa de aciertos porque el plano no permite separar correctamente las clases.


## Ejercicio 3

El algoritmo implementado se encuentra en el archivo "PerceptronMulticapa.R"

 -  Lectura de datos

```{r message=FALSE}
concentlite <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/concentlite.csv", col_names = FALSE)
```

 - Gráfica de datos con clase

```{r}
ggplot(data=concentlite, aes(x=X1, y=X2,color=X3))+geom_point()
```

 - Entrenamiento de perceptrón

```{r}
if (calcular) {
  resultado <- entrenarPerceptronM(concentlite, maxEpocas = 500, critFinalizacion = 0.9, nu=0.1,
                                 arquitectura = c(3,1))
}
concentlite <- cbind(concentlite,resultado$resultado)

```

- Gráfica con clasificación del perceptron

```{r}
ggplot(data=concentlite, aes(x=X1, y=X2, color=X3, shape=as.factor(resultado$resultado)))+geom_point()
```


```{r}

plot(resultado$error)

# Tasa de aciertos
resultado$tasa

# Cantidad de epocas
resultado$epocas

```

### Punto b

Incorporación del termino de momento.

Se agrega una variable alfa a la función, si la variable es cero no aplica el termino de momento.

```{r}
if (calcular) {
resultado2 <- entrenarPerceptronM(concentlite[,1:3], maxEpocas = 500, critFinalizacion = 0.9, nu=0.1,
                                 arquitectura = c(3,1), alfa = 0.5)
}

```


```{r}
plot(resultado2$error)

# Tasa de aciertos
resultado2$tasa

# Cantidad de epocas
resultado2$epocas
```


### Punto c

```{r}
# Calculo punto medio

concentliteMedio <- array()
concentliteMedio[1] <- mean(concentlite$X1)
concentliteMedio[2] <- mean(concentlite$X2)

# Agrego una columna con la distancia
concentlite$dist <- sqrt((concentlite$X1 - concentliteMedio[1])^2 + 
                    (concentlite$X2 - concentliteMedio[2])^2)
datos <- as.data.frame(cbind(concentlite[,"dist"], concentlite[,"X3"]))
# Entreno perceptrón simple
if (calcular) {
pesosConcentlite <- entrenarPerceptronSigmo(datos, maxEpocas = 100, critFinalizacion = 0.9,
                                               nu = 0.01)
}
# Modelo obtenido
pesosConcentlite$W

# Tasa
pesosConcentlite$tasa


```

```{r}
# Gráfica de error

plot(pesosConcentlite$error)


```

```{r}

# Guardamos los modelos generados
if (calcular) {
  save(resultado,resultado2,salidaPerceptronOR,salidaPerceptronXOR,
     pesosConcentlite,file = "resultados.RData")
}

```


### Preguntas:

- ¿Cuál es la arquitectura mínima que emplearía para resolver este problema? ¿Por qué?
 
 La arquitectura mínima es una capa de 3 neuronas y una capa de 1 neurona, esta fue la arquitectura utilizado para resolver la guía. Al estar una de las clases rodeada o contenida dentro de la otra clase, se requiere una arquitectura que genere una zona cerrada, para esto se requieren al menos tres rectas que definen una zona triangular. La arquitectura utilizada genera tres rectas con la primera capa de 3 neuronas y luego una capa de 1 neurona que a partir de la salida de las anteriores clasifica según si está dentro o fuera de esta zona triangular.
 
 - ¿El número de épocas requerido para entrenar un perceptrón multicapa se modifica al emplear el término de momento? Analice el efecto de este término de momento sobre el entrenamiento.
 
 El número de época al utilizar termino de momento se reduce. En nuestro caso, se ve que disminuye de 296 a 275. Para lograr esto se agrega un término a la corrección de los pesos utilizando el error del patrón anterior.

 - ¿Qué conclusión puede sacar a partir del ejercicio 3c?

 Del ejercicio 3c podemos concluir que es muy importante conocer todas las herramientas y entender bien el problema, en este caso el problema se podía resolver con una tasa de acierto mayor al 90% utilizando un perceptrón simple. Esto reduce los tiempos de entrenamiento y la complejidad del modelo.



```{r child = 'Guia1_ejercicio4.Rmd'}
```
  

