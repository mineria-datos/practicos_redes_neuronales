---
title: "Guia 2"
author: "Grupo 3"
date: "10/19/2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(mvtnorm)
library(cluster)
library(tidyverse)
source('./RedRBF_g2.R')
source('./PerceptronSimpleRBF_g2.R')
source('../Particiones.R')

if(file.exists('./resultadosG2.RData')) {
  load("./resultadosG2.RData")
  calcular = FALSE
}
#calcular = TRUE
```


## Ejercicio 1

### Resolución del problema XOR con una red neuronal RBF

 - Lectura de los patrones de entrenamiento
 
```{r message=FALSE}
XOR_trn <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/XOR_trn.csv", col_names = FALSE)
XOR_tst <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/XOR_tst.csv", col_names = FALSE)
```
 
 - Selección de parámetros y entrenamiento de perceptrón
 
En este caso se utilizan 4 gausianas por la distribución de los datos.

```{r}
datos_x <- XOR_trn[,c(1,2)]
datos_y <- XOR_trn[,3]
modeloRBF <- redRBF(datos_x, datos_y, nroGausianas = 4, funcion = "sigmo")
```

 - Prueba con datos de test
 
```{r}
datos_x <- XOR_tst[,c(1,2)]
datos_y <- XOR_tst[,3]
salida <- aplicarRedRBF(modeloRBF, datos_x, datos_y)
salida$tasa
```

### Resolución del problema Iris con una red neuronal RBF

 - Lectura de los patrones de entrenamiento

```{r message=FALSE}
irisbin <- read_csv("../../PUBLICO/Encuentro 1/Práctica/data/irisbin.csv", col_names = FALSE)
```

- Selección de parámetros y entrenamiento de perceptrón

```{r include=FALSE}
datos_x <- irisbin[,c(1,2,3,4)]
datos_y <- irisbin[,c(5,6,7)]

#Falta aplicar criterio de Elbow para la selección de K

modeloRBF <- redRBF(datos_x, datos_y, nroGausianas = 10, funcion = "sigmo", pnu = 0.2, 
                    pepoca = 200, pcritFinalizacion = 0.9)
```

 - Prueba con datos 
 
```{r}
salida <- aplicarRedRBF(modeloRBF, datos_x, datos_y)
salida$tasa

head(salida$salida)


```

Cantidad de parámetros:

En una red MLP con una estructura (3,1), tenemos los siguientes parámetros:

$numParamMLP = Parámetros de Capa 1 + Parámetros de Capa 2$

$numParamMLP = [(4 entradas + 1) * 3 neuronas] + [(3 entradas + 1) * 1 neurona]$

$numParamMLP = 5 * 3 + 4 * 1 = 19 parámetros$

Una red RBF con 19 parámetros podría tener la siguiente distribución:

$numParamRBF = Parámetros de Gausianas + Parámetros de Perceptrones$

$numParamRBF = [3 centros] + [(3 entradas + 1) * 3 neurona]$

$numParamRBF = 3 + 4 * 3 = 15 parámetros$

```{r include=FALSE}
modeloRBF_2 <- redRBF(datos_x, datos_y, nroGausianas = 3, funcion = "sigmo", pnu = 0.2, 
                    pepoca = 200, pcritFinalizacion = 0.9)
```

 - Prueba con datos 
 
```{r}
salida_2 <- aplicarRedRBF(modeloRBF_2, datos_x, datos_y)
salida_2$tasa

head(salida_2$salida)
```


## Ejercicio 2

 - Lectura de datos
 
```{r message=FALSE}
merval <- read_csv("../../PUBLICO/Encuentro 3/Práctica/data/merval.csv", col_names = FALSE)
```
 
 - Preprocesamiento de los datos
 
Generamos un dataset que contenga seis valores consecutivos en cada registro, cinco tomados como datos de entrada y un sexto valor tomado como clase.
 
```{r}
cantidadDatos <- nrow(merval)
datos_merval <- matrix(0,nrow = cantidadDatos-5, ncol = 6)

for (i in seq(1,cantidadDatos-5)) {
  datos_merval[i,] <- merval$X1[seq(i,i+5)] 
}

datos_x <- datos_merval[,c(1,2,3,4,5)] %>% as.matrix()
datos_y <- datos_merval[,6] %>% as.matrix()

# Primeros seis registros del dataset
head(datos_merval)

```

Antes de generar el modelo, tenemos que definir el número de gausianas. Utilizamos la gráfica de Elbow para definir el k a utilizar en el modelo.

```{r}
set.seed(123)
wss <- function(k) {
  kmeans(datos_x, k, nstart = 10 )$tot.withinss
}
# Valores de k = 1 a k = 15
k.values <- 1:15
wss_values <- map_dbl(k.values, wss)
plot(k.values, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Número de clusters K",
       ylab="Inercia - Suma de Cuadrados")
```

Mirando la gráfica anterior tomamos un valor de k = 4, es donde la gráfica hace el codo y queda aproximadamente constante.

 - Normalizamos los datos.
 
```{r}
maximo <- 0
for (i in seq(1,ncol(datos_x))) {
  if (max(datos_x[,i]) > maximo) {maximo <- max(datos_x[,i])} 
}
if (max(datos_y) > maximo) {maximo <- max(datos_y)}

datos_x <- datos_x / maximo
datos_y <- datos_y / maximo
```

 - Dividimos los datos en Train y Test, utilizando un 70% para entrenamiento.
 
```{r}
merval7030 <- generarParticionPorID(as.data.frame(datos_merval), porcEntrenamiento = 0.7, 
                                    semilla = 1, clase = "V6")

```

 - Generamos el modelo con los datos de entrenamiento.

```{r}

if (calcular) {
modeloMerval70 <- redRBF(datos_x[merval7030$trn,], (datos_y[merval7030$trn,] %>% as.matrix()), 
                         nroGausianas = 4, funcion = "lineal", pnu = 0.01, pepoca = 200000, 
                         pcritFinalizacion = 0.95, ptolerencia = 0.1)
}
```

 - Aplicamos el modelo a los datos de Train y Test 

```{r}
salidaMervalTrn <- aplicarRedRBF(modeloMerval70, datos_x[merval7030$trn,], 
                                 (datos_y[merval7030$trn,] %>% as.matrix()))
salidaMervalTst <- aplicarRedRBF(modeloMerval70, datos_x[merval7030$tst,], 
                                 (datos_y[merval7030$tst,] %>% as.matrix()))

```

 - Grafica de error en Test

```{r}
#Grafica de error en cada registro
plot(salidaMervalTst$error)

#Error cuadrático medio
errorMedio <- sum(salidaMervalTst$error) / length(salidaMervalTst$error)
errorMedio

```

 - Generamos el modelo a aplicar para realizar las predicciones con todos los datos.

```{r}
# Generamos el modelo
if (calcular) {
modeloMerval <- redRBF(datos_x, datos_y, nroGausianas = 4, funcion = "lineal", pnu = 0.01, 
                    pepoca = 200000, pcritFinalizacion = 0.95, ptolerencia = 0.1)
}

```


Aplicamos el modelo a los mismos datos de entrenamiento para graficar error en train.

```{r}

salidaMerval <- aplicarRedRBF(modeloMerval, datos_x, datos_y)

```

Grafica de error

```{r}
#Grafica de error en cada registro
plot(salidaMerval$error)

#Error cuadrático medio
errorMedio <- sum(salidaMerval$error) / length(salidaMerval$error)
errorMedio

```

 - Gráfica del valor predicho y el valor real

```{r}

plot(salidaMerval$salida * maximo, main = "Valores Predichos")
plot(datos_y * maximo, main = "Valores Reales")

```

 - Predecimos un nuevo valor
 
Tomamos los últimos 5 valores del dataset y predecimos cual será el próximo valor.

```{r}

ultimosDatos <- (merval[seq(nrow(merval)-4,nrow(merval)),] / maximo) %>% as.matrix()
ultimosDatos <- t(ultimosDatos)
ultimosDatos <- rbind(ultimosDatos,ultimosDatos) %>% as.matrix() 
#usamos dos registros por el tipo de datos.
salidaUno <- as.matrix(c(1,1)) 
salidaMervalNew <- aplicarRedRBF(modeloMerval, ultimosDatos, salidaUno)
#Nuevo valor predicho
salidaMervalNew$salida[1] * maximo
```



```{r}

# Guardamos los modelos generados
if (calcular) {
save(modeloMerval, modeloMerval70,file = "resultadosG2.RData")
}

```

